{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01ed21f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing orca context\n",
      "Current pyspark location is : /home/ojash/miniconda3/envs/py37/lib/python3.7/site-packages/pyspark/__init__.py\n",
      "Start to getOrCreate SparkContext\n",
      "pyspark_submit_args is:  --driver-class-path /home/ojash/miniconda3/envs/py37/lib/python3.7/site-packages/bigdl/share/core/lib/all-2.4.0-20230420.050641-1.jar:/home/ojash/miniconda3/envs/py37/lib/python3.7/site-packages/bigdl/share/orca/lib/bigdl-orca-spark_2.4.6-2.4.0-jar-with-dependencies.jar:/home/ojash/miniconda3/envs/py37/lib/python3.7/site-packages/bigdl/share/dllib/lib/bigdl-dllib-spark_2.4.6-2.4.0-jar-with-dependencies.jar pyspark-shell \n",
      "[main] WARN  org.apache.spark.util.Utils  - Your hostname, ojash-VMware-Virtual-Platform resolves to a loopback address: 127.0.1.1; using 192.168.186.129 instead (on interface ens33)\n",
      "[main] WARN  org.apache.spark.util.Utils  - Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "[main] WARN  org.apache.hadoop.util.NativeCodeLoader  - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread-4] WARN  org.apache.spark.util.Utils  - Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "2024-05-03 11:31:48,398 Thread-4 WARN The bufferSize is set to 4000 but bufferedIo is false: false\n",
      "2024-05-03 11:31:48,404 Thread-4 WARN The bufferSize is set to 4000 but bufferedIo is false: false\n",
      "2024-05-03 11:31:48,405 Thread-4 WARN The bufferSize is set to 4000 but bufferedIo is false: false\n",
      "2024-05-03 11:31:48,406 Thread-4 WARN The bufferSize is set to 4000 but bufferedIo is false: false\n",
      "24-05-03 11:31:48 [Thread-4] INFO  Engine$:122 - Auto detect executor number and executor cores number\n",
      "24-05-03 11:31:48 [Thread-4] INFO  Engine$:124 - Executor number is 1 and executor cores number is 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "User settings:\n",
      "\n",
      "   KMP_AFFINITY=granularity=fine,compact,1,0\n",
      "   KMP_BLOCKTIME=0\n",
      "   KMP_SETTINGS=1\n",
      "   OMP_NUM_THREADS=1\n",
      "\n",
      "Effective settings:\n",
      "\n",
      "   KMP_ABORT_DELAY=0\n",
      "   KMP_ADAPTIVE_LOCK_PROPS='1,1024'\n",
      "   KMP_ALIGN_ALLOC=64\n",
      "   KMP_ALL_THREADPRIVATE=128\n",
      "   KMP_ATOMIC_MODE=2\n",
      "   KMP_BLOCKTIME=0\n",
      "   KMP_CPUINFO_FILE: value is not defined\n",
      "   KMP_DETERMINISTIC_REDUCTION=false\n",
      "   KMP_DEVICE_THREAD_LIMIT=2147483647\n",
      "   KMP_DISP_HAND_THREAD=false\n",
      "   KMP_DISP_NUM_BUFFERS=7\n",
      "   KMP_DUPLICATE_LIB_OK=false\n",
      "   KMP_FORCE_REDUCTION: value is not defined\n",
      "   KMP_FOREIGN_THREADS_THREADPRIVATE=true\n",
      "   KMP_FORKJOIN_BARRIER='2,2'\n",
      "   KMP_FORKJOIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_FORKJOIN_FRAMES=true\n",
      "   KMP_FORKJOIN_FRAMES_MODE=3\n",
      "   KMP_GTID_MODE=3\n",
      "   KMP_HANDLE_SIGNALS=false\n",
      "   KMP_HOT_TEAMS_MAX_LEVEL=1\n",
      "   KMP_HOT_TEAMS_MODE=0\n",
      "   KMP_INIT_AT_FORK=true\n",
      "   KMP_INIT_WAIT=2048\n",
      "   KMP_ITT_PREPARE_DELAY=0\n",
      "   KMP_LIBRARY=throughput\n",
      "   KMP_LOCK_KIND=queuing\n",
      "   KMP_MALLOC_POOL_INCR=1M\n",
      "   KMP_NEXT_WAIT=1024\n",
      "   KMP_NUM_LOCKS_IN_BLOCK=1\n",
      "   KMP_PLAIN_BARRIER='2,2'\n",
      "   KMP_PLAIN_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_REDUCTION_BARRIER='1,1'\n",
      "   KMP_REDUCTION_BARRIER_PATTERN='hyper,hyper'\n",
      "   KMP_SCHEDULE='static,balanced;guided,iterative'\n",
      "   KMP_SETTINGS=true\n",
      "   KMP_SPIN_BACKOFF_PARAMS='4096,100'\n",
      "   KMP_STACKOFFSET=64\n",
      "   KMP_STACKPAD=0\n",
      "   KMP_STACKSIZE=4M\n",
      "   KMP_STORAGE_MAP=false\n",
      "   KMP_TASKING=2\n",
      "   KMP_TASKLOOP_MIN_TASKS=0\n",
      "   KMP_TASK_STEALING_CONSTRAINT=1\n",
      "   KMP_TEAMS_THREAD_LIMIT=8\n",
      "   KMP_TOPOLOGY_METHOD=all\n",
      "   KMP_USER_LEVEL_MWAIT=false\n",
      "   KMP_VERSION=false\n",
      "   KMP_WARNINGS=true\n",
      "   OMP_AFFINITY_FORMAT='OMP: pid %P tid %T thread %n bound to OS proc set {%a}'\n",
      "   OMP_ALLOCATOR=omp_default_mem_alloc\n",
      "   OMP_CANCELLATION=false\n",
      "   OMP_DEFAULT_DEVICE=0\n",
      "   OMP_DISPLAY_AFFINITY=false\n",
      "   OMP_DISPLAY_ENV=false\n",
      "   OMP_DYNAMIC=false\n",
      "   OMP_MAX_ACTIVE_LEVELS=2147483647\n",
      "   OMP_MAX_TASK_PRIORITY=0\n",
      "   OMP_NESTED=false\n",
      "   OMP_NUM_THREADS='1'\n",
      "   OMP_PLACES: value is not defined\n",
      "   OMP_PROC_BIND='intel'\n",
      "   OMP_SCHEDULE='static'\n",
      "   OMP_STACKSIZE=4M\n",
      "   OMP_TARGET_OFFLOAD=DEFAULT\n",
      "   OMP_THREAD_LIMIT=2147483647\n",
      "   OMP_TOOL=enabled\n",
      "   OMP_TOOL_LIBRARIES: value is not defined\n",
      "   OMP_WAIT_POLICY=PASSIVE\n",
      "   KMP_AFFINITY='noverbose,warnings,respect,granularity=fine,compact,1,0'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-05-03 11:31:49 [Thread-4] INFO  ThreadPool$:95 - Set mkl threads to 1 on thread 16\n",
      "[Thread-4] WARN  org.apache.spark.SparkContext  - Using an existing SparkContext; some configuration may not take effect.\n",
      "24-05-03 11:31:49 [Thread-4] INFO  Engine$:461 - Find existing spark context. Checking the spark conf...\n",
      "cls.getname: com.intel.analytics.bigdl.dllib.utils.python.api.Sample\n",
      "BigDLBasePickler registering: bigdl.dllib.utils.common  Sample\n",
      "cls.getname: com.intel.analytics.bigdl.dllib.utils.python.api.EvaluatedResult\n",
      "BigDLBasePickler registering: bigdl.dllib.utils.common  EvaluatedResult\n",
      "cls.getname: com.intel.analytics.bigdl.dllib.utils.python.api.JTensor\n",
      "BigDLBasePickler registering: bigdl.dllib.utils.common  JTensor\n",
      "cls.getname: com.intel.analytics.bigdl.dllib.utils.python.api.JActivity\n",
      "BigDLBasePickler registering: bigdl.dllib.utils.common  JActivity\n",
      "Successfully got a SparkContext\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 6) / 6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-05-03 11:31:53 [Executor task launch worker for task 4] INFO  Engine$:162 - Initializing JavaGatewayServer on executor-driver \n",
      "24-05-03 11:31:53 [Executor task launch worker for task 4] INFO  Engine$:182 - JavaGatewayServer initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from bigdl.orca import init_orca_context, stop_orca_context, OrcaContext\n",
    "\n",
    "# cluster_mode can be \"local\", \"k8s\" or \"yarn\"\n",
    "sc = init_orca_context(cluster_mode=\"local\", cores=6, memory=\"6g\", num_nodes=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0927c200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here, the Executor Number is 1 as the no of nodes is 1, Executor Core is 6 as we defined core as 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08e2bdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType\n",
    "from bigdl.orca import OrcaContext\n",
    "\n",
    "spark = OrcaContext.get_spark_session()\n",
    "\n",
    "num_users, num_items = 200, 100\n",
    "rdd = sc.range(0, 512).map(\n",
    "    lambda x: [random.randint(0, num_users-1), random.randint(0, num_items-1), random.randint(0, 1)])\n",
    "schema = StructType([StructField(\"user\", IntegerType(), False),\n",
    "                     StructField(\"item\", IntegerType(), False),\n",
    "                     StructField(\"label\", IntegerType(), False)])\n",
    "df = spark.createDataFrame(rdd, schema)\n",
    "train_df, test_df = df.randomSplit([0.8, 0.2], seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6486123e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 11:34:07.115279: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-03 11:34:07.400479: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-03 11:34:07.400503: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-03 11:34:10.188840: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-03 11:34:10.189060: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-03 11:34:10.189074: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "[Stage 9:>                                                          (0 + 1) / 1]2024-05-03 11:35:35.767844: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-03 11:35:36.444908: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-03 11:35:36.444969: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-03 11:35:39.788285: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-03 11:35:39.788449: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-03 11:35:39.788461: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "WARNING:tensorflow:From /home/ojash/miniconda3/envs/py37/lib/python3.7/site-packages/bigdl/orca/learn/tf2/spark_runner.py:340: _CollectiveAllReduceStrategyExperimental.__init__ (from tensorflow.python.distribute.collective_all_reduce_strategy) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "use distribute.MultiWorkerMirroredStrategy instead\n",
      "2024-05-03 11:35:55.609335: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2024-05-03 11:35:55.609409: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-05-03 11:35:55.609431: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ojash-VMware-Virtual-Platform): /proc/driver/nvidia/version does not exist\n",
      "2024-05-03 11:35:55.665773: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-03 11:35:55.758338: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:447] Started server with target: grpc://192.168.186.129:52187\n",
      "2024-05-03 11:35:55.792065: I tensorflow/core/distributed_runtime/coordination/coordination_service.cc:502] /job:worker/replica:0/task:0 has connected to coordination service. Incarnation: 5210802692002127237\n",
      "2024-05-03 11:35:55.792480: I tensorflow/core/distributed_runtime/coordination/coordination_service_agent.cc:277] Coordination agent has successfully connected.\n",
      "WARNING:tensorflow:From /home/ojash/miniconda3/envs/py37/lib/python3.7/site-packages/bigdl/orca/learn/tf2/spark_runner.py:147: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "2024-05-03 11:35:57.809431: W tensorflow/core/framework/dataset.cc:769] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
      "Epoch 1/4\n",
      "6/6 [==============================] - 3s 117ms/step - loss: 0.6930 - accuracy: 0.4766 - val_loss: 0.6984 - val_accuracy: 0.4219\n",
      "Epoch 2/4\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 0.6909 - accuracy: 0.5391 - val_loss: 0.6995 - val_accuracy: 0.4219\n",
      "Epoch 3/4\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.6904 - accuracy: 0.5443 - val_loss: 0.7004 - val_accuracy: 0.3750\n",
      "Epoch 4/4\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.6862 - accuracy: 0.6016 - val_loss: 0.7016 - val_accuracy: 0.3281\n",
      "2024-05-03 11:36:01.712307: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[Stage 10:>                                                         (0 + 1) / 1]2024-05-03 11:36:01.995342: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-05-03 11:36:01.995378: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-03 11:36:03.534500: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-03 11:36:03.534763: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-05-03 11:36:03.534822: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2024-05-03 11:36:05.262588: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2024-05-03 11:36:05.262621: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-05-03 11:36:05.262641: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ojash-VMware-Virtual-Platform): /proc/driver/nvidia/version does not exist\n",
      "2024-05-03 11:36:05.263116: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from bigdl.orca.learn.tf2.estimator import Estimator\n",
    "\n",
    "# Define the NCF model in standard TensorFlow API\n",
    "def model_creator(config):\n",
    "    from tensorflow import keras\n",
    "\n",
    "    user_input = keras.layers.Input(shape=(1,), dtype=\"int32\", name=\"use_input\")\n",
    "    item_input = keras.layers.Input(shape=(1,), dtype=\"int32\", name=\"item_input\")\n",
    "\n",
    "    mlp_embed_user = keras.layers.Embedding(input_dim=config[\"num_users\"], output_dim=config[\"embed_dim\"],\n",
    "                                            input_length=1)(user_input)\n",
    "    mlp_embed_item = keras.layers.Embedding(input_dim=config[\"num_items\"], output_dim=config[\"embed_dim\"],\n",
    "                                            input_length=1)(item_input)\n",
    "\n",
    "    user_latent = keras.layers.Flatten()(mlp_embed_user)\n",
    "    item_latent = keras.layers.Flatten()(mlp_embed_item)\n",
    "\n",
    "    mlp_latent = keras.layers.concatenate([user_latent, item_latent], axis=1)\n",
    "    predictions = keras.layers.Dense(1, activation=\"sigmoid\")(mlp_latent)\n",
    "    model = keras.models.Model(inputs=[user_input, item_input], outputs=predictions)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "train_steps = int(train_df.count() / batch_size)\n",
    "val_steps = int(test_df.count() / batch_size)\n",
    "\n",
    "est = Estimator.from_keras(model_creator=model_creator, backend=\"spark\",\n",
    "                           config={\"embed_dim\": 8, \"num_users\": num_users, \"num_items\": num_items})\n",
    "\n",
    "# Distributed training\n",
    "est.fit(data=train_df,\n",
    "        batch_size=batch_size,\n",
    "        epochs=4,\n",
    "        feature_cols=['user', 'item'],\n",
    "        label_cols=['label'],\n",
    "        steps_per_epoch=train_steps,\n",
    "        validation_data=test_df,\n",
    "        validation_steps=val_steps)\n",
    "\n",
    "# Distributed inference\n",
    "prediction_df = est.predict(test_df,\n",
    "                            batch_size=batch_size,\n",
    "                            feature_cols=['user', 'item'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "645e3820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping orca context\n"
     ]
    }
   ],
   "source": [
    "stop_orca_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075cf5ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
